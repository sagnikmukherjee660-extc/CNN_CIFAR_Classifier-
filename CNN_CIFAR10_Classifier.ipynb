{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sagnikmukherjee660-extc/CNN_CIFAR_Classifier-/blob/main/CNN_CIFAR10_Classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_X-_SEbXPYU",
        "outputId": "6d015cc6-7848-4b00-898f-34bce6559edc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras-tuner\n",
            "  Downloading keras_tuner-1.4.7-py3-none-any.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.12/dist-packages (from keras-tuner) (3.10.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from keras-tuner) (25.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from keras-tuner) (2.32.4)\n",
            "Collecting kt-legacy (from keras-tuner)\n",
            "  Downloading kt_legacy-1.0.5-py3-none-any.whl.metadata (221 bytes)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.12/dist-packages (from keras->keras-tuner) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from keras->keras-tuner) (2.0.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras->keras-tuner) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras->keras-tuner) (0.1.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.12/dist-packages (from keras->keras-tuner) (3.14.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras->keras-tuner) (0.17.0)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.12/dist-packages (from keras->keras-tuner) (0.5.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->keras-tuner) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->keras-tuner) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->keras-tuner) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->keras-tuner) (2025.8.3)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.12/dist-packages (from optree->keras->keras-tuner) (4.15.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras->keras-tuner) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras->keras-tuner) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras->keras-tuner) (0.1.2)\n",
            "Downloading keras_tuner-1.4.7-py3-none-any.whl (129 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.1/129.1 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
            "Installing collected packages: kt-legacy, keras-tuner\n",
            "Successfully installed keras-tuner-1.4.7 kt-legacy-1.0.5\n"
          ]
        }
      ],
      "source": [
        "!pip install keras-tuner"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eaER49iZa8V9"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, utils\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
        "import keras_tuner as kt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "db4L2M2WbCaR"
      },
      "source": [
        "Load & preprocess CIFAR‑10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0jma0YZjbFEA",
        "outputId": "f7b59c88-8f63-4bc3-f116-39e16e98450b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 0us/step\n"
          ]
        }
      ],
      "source": [
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
        "x_train = x_train.astype('float32') / 255.0\n",
        "x_test  = x_test.astype('float32') / 255.0\n",
        "y_train = utils.to_categorical(y_train, 10)\n",
        "y_test  = utils.to_categorical(y_test, 10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3lGjSLqbKm5"
      },
      "source": [
        "MixUp data generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t3Nr6j1vbNHF"
      },
      "outputs": [],
      "source": [
        "def mixup_generator(x, y, batch_size=128, alpha=0.2):\n",
        "    n = x.shape[0]\n",
        "    idx = np.arange(n)\n",
        "    while True:\n",
        "        np.random.shuffle(idx)\n",
        "        for i in range(0, n, batch_size):\n",
        "            batch_idx = idx[i : i + batch_size]\n",
        "            x1, y1 = x[batch_idx].copy(), y[batch_idx].copy()\n",
        "            lam = np.random.beta(alpha, alpha, size=len(x1))\n",
        "            lam_x = lam.reshape(-1,1,1,1)\n",
        "            lam_y = lam.reshape(-1,1)\n",
        "            idx2 = np.random.choice(n, size=len(x1), replace=False)\n",
        "            x2, y2 = x[idx2], y[idx2]\n",
        "            x_batch = lam_x * x1 + (1 - lam_x) * x2\n",
        "            y_batch = lam_y * y1 + (1 - lam_y) * y2\n",
        "            yield x_batch, y_batch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-rJkEP6sbQU0"
      },
      "source": [
        "Build tunable model using ResNet50 backbone"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kBhstN-EbT7m"
      },
      "outputs": [],
      "source": [
        "def build_model(hp):\n",
        "    # Backbone\n",
        "    base = tf.keras.applications.ResNet50(\n",
        "        include_top=False,\n",
        "        weights='imagenet',\n",
        "        input_shape=(32,32,3),\n",
        "        pooling='avg'\n",
        "    )\n",
        "    base.trainable = False\n",
        "\n",
        "    inputs = layers.Input(shape=(32,32,3))\n",
        "    x = tf.keras.applications.resnet.preprocess_input(inputs)\n",
        "    x = base(x, training=False)\n",
        "\n",
        "    # Tunable dense layer size\n",
        "    units = hp.Choice('dense_units', [128, 256, 512], default=256)\n",
        "    x = layers.Dense(units, activation='relu')(x)\n",
        "    x = layers.Dropout(\n",
        "        hp.Float('dropout_rate', min_value=0.3, max_value=0.6, step=0.1, default=0.5)\n",
        "    )(x)\n",
        "\n",
        "    outputs = layers.Dense(10, activation='softmax')(x)\n",
        "    model = models.Model(inputs, outputs)\n",
        "\n",
        "    # Compile with tunable learning rate and label smoothing\n",
        "    lr = hp.Float('learning_rate', 1e-4, 1e-2, sampling='log', default=1e-3)\n",
        "    loss = tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.1)\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=lr),\n",
        "        loss=loss,\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FfQeIXvWbX7C"
      },
      "source": [
        "Set up Keras Tuner (Hyperband)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZRf4p6E1bavg",
        "outputId": "1a722f71-c815-4481-e20f-1b703d921147"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ],
      "source": [
        "tuner = kt.Hyperband(\n",
        "    build_model,\n",
        "    objective='val_accuracy',\n",
        "    max_epochs=20,\n",
        "    factor=3,\n",
        "    directory='cifar5_tuner',\n",
        "    project_name='episode5'\n",
        ")\n",
        "\n",
        "# Early stopping during tuning\n",
        "stop_early = EarlyStopping(monitor='val_accuracy', patience=5, verbose=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X0wseujPbgyq"
      },
      "source": [
        "Run hyperparameter search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ONSfxENHbhb3",
        "outputId": "996d9ef1-ec0c-498e-c49a-f94ed8fc1dad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "\u001b[1m390/390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m238s\u001b[0m 578ms/step - accuracy: 0.1434 - loss: 2.3849 - val_accuracy: 0.2553 - val_loss: 2.1395\n",
            "Epoch 2/3\n",
            "\u001b[1m110/390\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:04\u001b[0m 445ms/step - accuracy: 0.2085 - loss: 2.1884"
          ]
        }
      ],
      "source": [
        "batch_size = 128\n",
        "steps_per_epoch = x_train.shape[0] // batch_size\n",
        "\n",
        "tuner.search(\n",
        "    mixup_generator(x_train, y_train, batch_size=batch_size, alpha=0.2),\n",
        "    steps_per_epoch=steps_per_epoch,\n",
        "    validation_data=(x_test, y_test),\n",
        "    epochs=20,\n",
        "    callbacks=[stop_early]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5DrBENL_d2co"
      },
      "source": [
        "Retrieve the best model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d4LTBNVFd3ZF"
      },
      "outputs": [],
      "source": [
        "best_model = tuner.get_best_models(num_models=1)[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fCTba0MHd6Bf"
      },
      "source": [
        "Fine Tune"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VAzsF3zceCvq"
      },
      "outputs": [],
      "source": [
        "fine_tune_history = best_model.fit(\n",
        "    mixup_generator(x_train, y_train, batch_size=batch_size, alpha=0.2),\n",
        "    steps_per_epoch=steps_per_epoch,\n",
        "    validation_data=(x_test, y_test),\n",
        "    epochs=10,\n",
        "    callbacks=[\n",
        "        ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1),\n",
        "        EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True, verbose=1)\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QCW8qj8meIv7"
      },
      "source": [
        "Final evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tPvwb_E6eJQw"
      },
      "outputs": [],
      "source": [
        "test_loss, test_acc = best_model.evaluate(x_test, y_test, verbose=2)\n",
        "print(f\"Final test accuracy: {test_acc:.4f}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOSajrGsKKGWGS8ozhcDEj2",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}